import os
import logging
from typing import Dict, Any, List
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from settings import settings

logger = logging.getLogger(__name__)

class AIClient:
    """Google AI client for negotiation message generation."""

    def __init__(self):
        self.api_key = settings.google_api_key
        self.model_name = settings.google_model
        self._client = None
        self._init_error = None

        # Validate API key format
        if self.api_key:
            if not self.api_key.startswith('AIza'):
                logger.error(f"[AI] Invalid Google API key format. Expected to start with 'AIza', got: {self.api_key[:10]}...")
                self._init_error = "Invalid API key format"
                self.api_key = None
            elif len(self.api_key) < 20:
                logger.error(f"[AI] Google API key too short. Expected at least 20 characters, got: {len(self.api_key)}")
                self._init_error = "API key too short"
                self.api_key = None

        if self.api_key:
            try:
                logger.info(f"[AI] Initializing Google AI with model: {self.model_name}")
                genai.configure(api_key=self.api_key)
                self._client = genai.GenerativeModel(
                    model_name=self.model_name,
                    safety_settings={
                        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
                        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
                    }
                )
                # Test the connection with a simple prompt
                test_result = self._client.generate_content("Hello")
                if test_result and test_result.text:
                    logger.info(f"[AI] âœ… Google AI successfully initialized with model: {self.model_name}")
                else:
                    logger.warning("[AI] Google AI initialization test failed - using mock responses")
                    self._client = None
                    self._init_error = "API test failed"
            except Exception as e:
                logger.error(f"[AI] âŒ Failed to initialize Google AI: {type(e).__name__}: {str(e)}")
                self._client = None
                self._init_error = str(e)
                # Provide helpful guidance based on error type
                if "permission" in str(e).lower() or "forbidden" in str(e).lower():
                    logger.error("[AI] API key appears to be invalid or lacks permissions. Please check your Google AI Studio API key.")
                elif "quota" in str(e).lower() or "limit" in str(e).lower():
                    logger.error("[AI] API quota exceeded. Please check your Google AI usage limits.")
                elif "network" in str(e).lower() or "connection" in str(e).lower():
                    logger.error("[AI] Network connection failed. Please check your internet connection.")
                else:
                    logger.error("[AI] Using mock responses due to initialization failure.")
        else:
            logger.warning("[AI] âš ï¸  No valid GOOGLE_API_KEY provided - using intelligent mock responses")
            self._init_error = "No API key provided"

    def is_available(self) -> bool:
        return self._client is not None

    def get_status(self) -> Dict[str, Any]:
        """Get detailed AI client status."""
        return {
            "is_available": self.is_available(),
            "api_key_configured": bool(self.api_key),
            "model_name": self.model_name,
            "init_error": self._init_error,
            "using_mock": not self.is_available()
        }

    async def generate_next_reply(
        self,
        history: List[Dict[str, str]],
        supplier_text: str,
        goals: Dict[str, Any],
        product_url: str,
        locale: str = "zh"
    ) -> Dict[str, Any]:
        """
        Generate the next negotiation reply based on conversation history and goals.

        Args:
            history: List of previous messages with 'role' and 'text'
            supplier_text: Latest supplier message
            goals: Negotiation goals dictionary
            product_url: Product page URL
            locale: Language preference ('zh', 'en', etc.)

        Returns:
            Dict with 'text', 'used_model', 'is_mock' keys
        """

        if not self.is_available():
            return self._generate_mock_response(history, supplier_text, goals, locale)

        try:
            # Build context from history
            context_history = "\n".join([f"{msg['role']}: {msg['text']}" for msg in history])

            # Build goals text
            goals_text = []
            if goals.get('target_price'):
                goals_text.append(f"Target price: {goals['target_price']}")
            if goals.get('moq'):
                goals_text.append(f"MOQ: {goals['moq']}")
            if goals.get('lead_time'):
                goals_text.append(f"Lead time: {goals['lead_time']}")
            if goals.get('quality_requirements'):
                goals_text.append(f"Quality: {goals['quality_requirements']}")
            if goals.get('samples'):
                goals_text.append("Request samples")
            if goals.get('shipping_terms'):
                goals_text.append(f"Shipping: {goals['shipping_terms']}")
            if goals.get('payment_terms'):
                goals_text.append(f"Payment: {goals['payment_terms']}")
            if goals.get('style'):
                goals_text.append(f"Style: {goals['style']}")

            goals_str = "\n".join(goals_text) if goals_text else "Standard B2B inquiry"

            # Determine language
            is_chinese_context = (
                locale == "zh" or
                any(c in supplier_text for c in "çš„ä½ äº†æ˜¯åœ¨æœ‰æˆ‘ä»–å¯¹å¥¹è¿™é‚£ä¹‹ä¸ªå¾—åœ°") or
                len(history) > 0 and any(c in history[0].get('text', '') for c in "çš„ä½ äº†æ˜¯åœ¨æœ‰æˆ‘ä»–å¯¹å¥¹è¿™é‚£ä¹‹ä¸ªå¾—åœ°")
            )

            # Check for aggressive style
            is_aggressive = goals.get('style', '').lower() == 'aggressive'

            # Build prompt
            if is_chinese_context:
                style_instruction = "ä½¿ç”¨æ¿€è¿›çš„è°ˆåˆ¤è¯­æ°”ï¼Œä¸“æ³¨äºæ¨åŠ¨æ›´å¥½çš„ä»·æ ¼å’Œæ›´å¿«çš„äº¤è´§æœŸã€‚" if is_aggressive else "ä¿æŒç¤¼è²Œå’Œä¸“ä¸šã€‚"
                prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„1688é‡‡è´­è°ˆåˆ¤åŠ©æ‰‹ã€‚è¯·æ ¹æ®å¯¹è¯å†å²å’Œé‡‡è´­ç›®æ ‡ç”Ÿæˆç®€æ´çš„å›å¤ã€‚

äº§å“é“¾æ¥: {product_url}

é‡‡è´­ç›®æ ‡:
{goals_str}

å¯¹è¯å†å²:
{context_history}

ä¾›åº”å•†æœ€æ–°æ¶ˆæ¯: "{supplier_text}"

{style_instruction}

è¯·ç”Ÿæˆ1-2å¥è¯çš„å›å¤ï¼Œä¸“æ³¨äºæœªè§£å†³çš„å…³é”®ä¿¡æ¯ï¼ˆä»·æ ¼ã€MOQã€äº¤æœŸã€æ ·å“ç­‰ï¼‰ã€‚å¦‚æœä¾›åº”å•†ç”¨ä¸­æ–‡å›å¤ï¼Œè¯·ç”¨ä¸­æ–‡å›å¤ã€‚"""
            else:
                style_instruction = "Use an aggressive negotiation tone focused on pushing better prices and faster delivery." if is_aggressive else "Be professional and goal-oriented."
                prompt = f"""You are a professional B2B negotiation assistant for 1688.com. Generate a concise reply based on conversation history and goals.

Product URL: {product_url}

Goals:
{goals_str}

Conversation History:
{context_history}

Latest supplier message: "{supplier_text}"

{style_instruction}

Generate a 1-2 sentence reply focusing on missing key details (price, MOQ, lead time, samples, etc.). Use simple English unless supplier uses Chinese."""

            # Generate response
            result = self._client.generate_content(prompt)
            text = result.text.strip()

            if not text:
                logger.warning("[AI] Empty response from Google AI, using mock")
                return self._generate_mock_response(history, supplier_text, goals, locale)

            logger.info(f"[AI]  Generated reply via {self.model_name}: {text[:100]}...")
            return {
                "text": text,
                "used_model": self.model_name,
                "is_mock": False
            }

        except Exception as e:
            logger.error(f"[AI]  API call failed: {e}, falling back to mock")
            return self._generate_mock_response(history, supplier_text, goals, locale)

    def _generate_mock_response(
        self,
        history: List[Dict[str, str]],
        supplier_text: str,
        goals: Dict[str, Any],
        locale: str = "zh"
    ) -> Dict[str, Any]:
        """Generate an intelligent mock response when AI is unavailable."""

        # Check if supplier mentioned specific details we should follow up on
        supplier_lower = supplier_text.lower()

        # Determine language with better detection
        is_chinese_context = (
            locale == "zh" or
            any(c in supplier_text for c in "çš„ä½ äº†æ˜¯åœ¨æœ‰æˆ‘ä»–å¯¹å¥¹è¿™é‚£ä¹‹ä¸ªå¾—åœ°") or
            (len(history) > 0 and any(c in history[0].get('text', '') for c in "çš„ä½ äº†æ˜¯åœ¨æœ‰æˆ‘ä»–å¯¹å¥¹è¿™é‚£ä¹‹ä¸ªå¾—åœ°"))
        )

        # Determine conversation stage
        turn_count = len(history)
        is_early_stage = turn_count <= 2
        is_mid_stage = 2 < turn_count <= 4
        is_late_stage = turn_count > 4

        # Extract context from history
        price_mentioned = any('price' in msg.get('text', '').lower() or 'ä»·æ ¼' in msg.get('text', '') or 'å…ƒ' in msg.get('text', '') for msg in history)
        moq_mentioned = any('moq' in msg.get('text', '').lower() or 'èµ·è®¢' in msg.get('text', '') for msg in history)
        lead_time_mentioned = any('lead time' in msg.get('text', '').lower() or 'äº¤æœŸ' in msg.get('text', '') for msg in history)

        # Priority-based intelligent responses
        mock_response = ""

        # Handle direct questions from supplier
        if any(keyword in supplier_lower for keyword in ['what', 'ä»€ä¹ˆ', 'how', 'å¦‚ä½•', 'which', 'å“ªä¸ª']):
            if is_chinese_context:
                mock_response = "æˆ‘ä»¬æ­£åœ¨è¯„ä¼°å¤šä¸ªä¾›åº”å•†ï¼Œéœ€è¦æ¯”è¾ƒä»·æ ¼å’ŒæœåŠ¡ã€‚è¯·æä¾›è¯¦ç»†çš„æŠ¥ä»·ä¿¡æ¯ã€‚"
            else:
                mock_response = "We're evaluating multiple suppliers and need to compare pricing and services. Please provide detailed quotation information."

        # Price-related responses
        elif any(keyword in supplier_lower for keyword in ['price', 'ä»·æ ¼', 'yuan', 'å…ƒ', '$', 'cost', 'è´¹ç”¨']):
            if is_early_stage:
                if is_chinese_context:
                    mock_response = "è°¢è°¢æŠ¥ä»·ã€‚è¯·é—®æœ€å°èµ·è®¢é‡æ˜¯å¤šå°‘ï¼Ÿäº¤è´§æœŸå¤šä¹…ï¼Ÿæ”¯æŒå®šåˆ¶å’Œå¼€å¢ç¥¨å—ï¼Ÿ"
                else:
                    mock_response = "Thank you for the pricing. What is the MOQ and lead time? Do you support customization and VAT invoices?"
            elif is_mid_stage:
                if is_chinese_context:
                    mock_response = "äº†è§£äº†ä»·æ ¼ã€‚å¦‚æœè®¢è´­1000ä»¶ä»¥ä¸Šï¼Œä»·æ ¼èƒ½ä¼˜æƒ å¤šå°‘ï¼Ÿæ ·å“è´¹ç”¨å¦‚ä½•è®¡ç®—ï¼Ÿ"
                else:
                    mock_response = "Price noted. Any discount for orders over 1000 pieces? How about sample costs?"
            else:
                if is_chinese_context:
                    mock_response = "ä»·æ ¼åŸºæœ¬ç¡®è®¤ã€‚è¯·é—®ä»˜æ¬¾æ–¹å¼æ˜¯ä»€ä¹ˆï¼Ÿæ˜¯å¦æ”¯æŒåˆ†æœŸä»˜æ¬¾ï¼Ÿ"
                else:
                    mock_response = "Price is mostly confirmed. What are the payment terms? Do you support installment payments?"

        # MOQ-related responses
        elif any(keyword in supplier_lower for keyword in ['moq', 'èµ·è®¢', 'quantity', 'æ•°é‡', 'minimum']):
            if is_chinese_context:
                mock_response = "MOQäº†è§£äº†ã€‚è¯·é—®è¿™ä¸ªä»·æ ¼å¯¹åº”å¤šå°‘æ•°é‡ï¼Ÿæ˜¯å¦åŒ…å«è¿è´¹å’Œç¨è´¹ï¼Ÿ"
            else:
                mock_response = "MOQ understood. Does this price include shipping and taxes? What about sample availability?"

        # Lead time/delivery responses
        elif any(keyword in supplier_lower for keyword in ['lead time', 'äº¤æœŸ', 'delivery', 'delivery time', 'production', 'ç”Ÿäº§']):
            if is_chinese_context:
                mock_response = "äº¤æœŸç¡®è®¤ã€‚è¯·é—®æ ·å“åˆ¶ä½œæ—¶é—´å¤šä¹…ï¼ŸåŠ æ€¥è®¢å•å¦‚ä½•å¤„ç†ï¼Ÿ"
            else:
                mock_response = "Lead time confirmed. How long for sample production? Can you handle rush orders?"

        # Quality/certification responses
        elif any(keyword in supplier_lower for keyword in ['quality', 'è´¨é‡', 'certification', 'è®¤è¯', 'standard', 'æ ‡å‡†']):
            if is_chinese_context:
                mock_response = "è´¨é‡æ ‡å‡†å¾ˆé‡è¦ã€‚è¯·é—®æœ‰å“ªäº›è®¤è¯è¯ä¹¦ï¼Ÿæ˜¯å¦æ”¯æŒç¬¬ä¸‰æ–¹éªŒè´§ï¼Ÿ"
            else:
                mock_response = "Quality standards are important. What certifications do you have? Do you support third-party inspection?"

        # Customization responses
        elif any(keyword in supplier_lower for keyword in ['custom', 'å®šåˆ¶', 'customize', 'oem', 'odm']):
            if is_chinese_context:
                mock_response = "å®šåˆ¶éœ€æ±‚å¯ä»¥è®¨è®ºã€‚è¯·é—®å®šåˆ¶è´¹ç”¨å’Œæœ€ä½èµ·è®¢é‡æ˜¯å¤šå°‘ï¼Ÿ"
            else:
                mock_response = "Customization can be discussed. What are the costs and MOQ for customized orders?"

        # Sample requests
        elif any(keyword in supplier_lower for keyword in ['sample', 'æ ·å“', 'specimen', 'æ ·å“è´¹']):
            if is_chinese_context:
                mock_response = "æ ·å“éœ€è¦ç¡®è®¤è´¨é‡ã€‚è¯·é—®æ ·å“è´¹ç”¨å¤šå°‘ï¼Ÿæ˜¯å¦å¯ä»¥é€€è¿˜ï¼Ÿ"
            else:
                mock_response = "We need samples for quality confirmation. What's the sample cost? Is it refundable?"

        # Default intelligent responses based on conversation stage and goals
        else:
            if is_early_stage:
                # Early stage: gather basic information
                if goals.get('target_price'):
                    if is_chinese_context:
                        mock_response = "è°¢è°¢å›å¤ã€‚æˆ‘ä»¬çš„ç›®æ ‡ä»·æ ¼èŒƒå›´æ˜¯å¤šå°‘ï¼Ÿé‡å¤§èƒ½ä¼˜æƒ å—ï¼Ÿ"
                    else:
                        mock_response = "Thanks for your reply. What's your target price range? Any discount for bulk orders?"
                else:
                    if is_chinese_context:
                        mock_response = "è°¢è°¢ï¼Œæˆ‘æƒ³äº†è§£æ›´å¤šäº§å“è¯¦æƒ…ã€‚è¯·é—®æœ€å°èµ·è®¢é‡ã€å•ä»·åŒºé—´å’Œäº¤è´§æœŸï¼Ÿ"
                    else:
                        mock_response = "Thank you, I'd like more product details. What are the MOQ, price range, and lead time?"

            elif is_mid_stage:
                # Mid stage: negotiate specific terms
                if is_chinese_context:
                    mock_response = "åŸºæœ¬äº†è§£äº†ã€‚è¯·é—®ä»˜æ¬¾æ–¹å¼æ˜¯ä»€ä¹ˆï¼Ÿæ˜¯å¦æ”¯æŒ30%å®šé‡‘ï¼Œ70%å‘è´§å‰ä»˜æ¸…ï¼Ÿ"
                else:
                    mock_response = "Basic information understood. What are the payment terms? Do you support 30% deposit, 70% before shipment?"

            else:
                # Late stage: final confirmation
                if is_chinese_context:
                    mock_response = "æ¡ä»¶åŸºæœ¬ç¡®è®¤ï¼Œæˆ‘éœ€è¦å’Œå›¢é˜Ÿè®¨è®ºä¸€ä¸‹ã€‚è¯·é—®æŠ¥ä»·æœ‰æ•ˆæœŸå¤šä¹…ï¼Ÿ"
                else:
                    mock_response = "Terms are mostly confirmed. I need to discuss with my team. How long is the quotation valid?"

        # Add AI mode indicator to response for transparency
        mode_indicator = "ğŸ¤– [æ™ºèƒ½æ¨¡å¼] " if not self.is_available() else ""

        logger.info(f"[AI] ğŸ¤– Generated intelligent mock response: {mock_response}")
        return {
            "text": mock_response,
            "used_model": "mock-enhanced",
            "is_mock": True,
            "ai_status": self.get_status()
        }

# Global AI client instance
ai_client = AIClient()